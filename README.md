# ETL-with-Pyspark

This is the final project of the course. The goal isto use pyspark on a project of our choice. These are the steps I did to complete the project:

1) Create pyspark and hadoop environment in desktop

    1 - Dowload Apache Spark from https://spark.apache.org/downloads.html
    
    2 - follow apache spark installation as in https://phoenixnap.com/kb/install-spark-on-windows-10 until end of step7

2) Create database in MongoDB

    1 - Install MongoDB Compass
    
    2 - Create database and collections
    
 3) Create ETL script in Jupyter Notebook
 
 4) Save data in SQL 
 
    1 -Dowload the connector from: https://dev.mysql.com/downloads/connector/j/
    
    2 - Put jar file in jar directory of Spark (C:\\Spark\jars) in my case
 
 5) Vizualize the data in PowerBI






