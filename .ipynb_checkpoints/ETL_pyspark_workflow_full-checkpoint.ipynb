{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88fcc6a-6dbd-4ded-8017-c6da40578e23",
   "metadata": {},
   "source": [
    "## Imports and Initialization of script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b684bb0a-46de-4a1b-a2ac-a10eca7a2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\marta\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\marta\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['HADOOP_HOME'] = \"C:\\Hadoop\"\n",
    "sys.path.append(\"C:\\Hadoop\\bin\")\n",
    "\n",
    "os.environ['JAVA_HOME'] = \"C:\\Java\"\n",
    "sys.path.append(\"C:\\Java\\bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a531b7-77ec-47b0-8ab0-6e2e6355bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,count, round, col, asc, DataFrame, expr, split, lit\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from functools import reduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe50dca-e3f1-4c89-9c39-6323f3b97d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "builder.\\\n",
    "appName(\"pyspark-notebook2\").\\\n",
    "master(\"local\").\\\n",
    "config(\"spark.executor.memory\", \"1g\").\\\n",
    "config(\"spark.mongodb.input.uri\",\"mongodb://127.0.0.1/Project6\").\\\n",
    "config(\"spark.mongodb.output.uri\",\"mongodb://127.0.0.1/Project6\").\\\n",
    "config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "config(\"spark.jars\", \"\\Spark\\spark-3.3.1-bin-hadoop3\\jars\\mysql-connector-j-8.0.32.jar\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd8c3b-dd1b-4aeb-accf-536b51949d0d",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36aa5ae5-e681-43c9-9913-b987b73b05f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o43.load.\n: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=localhost:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.ConnectException: Connection refused: connect}}]\r\n\tat com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:177)\r\n\tat com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)\r\n\tat com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:147)\r\n\tat com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:98)\r\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:278)\r\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:182)\r\n\tat com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:194)\r\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:163)\r\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:158)\r\n\tat com.mongodb.spark.MongoConnector.$anonfun$hasSampleAggregateOperator$1(MongoConnector.scala:234)\r\n\tat com.mongodb.spark.MongoConnector.$anonfun$withDatabaseDo$1(MongoConnector.scala:171)\r\n\tat com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:154)\r\n\tat com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:171)\r\n\tat com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:234)\r\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)\r\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)\r\n\tat com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)\r\n\tat com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)\r\n\tat com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:171)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     df_collection \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\\\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcom.mongodb.spark.sql.DefaultSource\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb://localhost:27017/Project6\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject6\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection\u001b[39m\u001b[38;5;124m\"\u001b[39m, collection) \\\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_collection\n\u001b[1;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextract_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mextract_collection\u001b[1;34m(collection)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_collection\u001b[39m(collection):\n\u001b[0;32m      7\u001b[0m     spark\u001b[38;5;241m.\u001b[39mconf\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspark.sql.caseSensitive\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m     df_collection \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcom.mongodb.spark.sql.DefaultSource\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongodb://localhost:27017/Project6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatabase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProject6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_collection\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\readwriter.py:184\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o43.load.\n: com.mongodb.MongoTimeoutException: Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=localhost:27017, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoSocketOpenException: Exception opening socket}, caused by {java.net.ConnectException: Connection refused: connect}}]\r\n\tat com.mongodb.internal.connection.BaseCluster.getDescription(BaseCluster.java:177)\r\n\tat com.mongodb.internal.connection.SingleServerCluster.getDescription(SingleServerCluster.java:41)\r\n\tat com.mongodb.client.internal.MongoClientDelegate.getConnectedClusterDescription(MongoClientDelegate.java:147)\r\n\tat com.mongodb.client.internal.MongoClientDelegate.createClientSession(MongoClientDelegate.java:98)\r\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.getClientSession(MongoClientDelegate.java:278)\r\n\tat com.mongodb.client.internal.MongoClientDelegate$DelegateOperationExecutor.execute(MongoClientDelegate.java:182)\r\n\tat com.mongodb.client.internal.MongoDatabaseImpl.executeCommand(MongoDatabaseImpl.java:194)\r\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:163)\r\n\tat com.mongodb.client.internal.MongoDatabaseImpl.runCommand(MongoDatabaseImpl.java:158)\r\n\tat com.mongodb.spark.MongoConnector.$anonfun$hasSampleAggregateOperator$1(MongoConnector.scala:234)\r\n\tat com.mongodb.spark.MongoConnector.$anonfun$withDatabaseDo$1(MongoConnector.scala:171)\r\n\tat com.mongodb.spark.MongoConnector.withMongoClientDo(MongoConnector.scala:154)\r\n\tat com.mongodb.spark.MongoConnector.withDatabaseDo(MongoConnector.scala:171)\r\n\tat com.mongodb.spark.MongoConnector.hasSampleAggregateOperator(MongoConnector.scala:234)\r\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator$lzycompute(MongoRDD.scala:221)\r\n\tat com.mongodb.spark.rdd.MongoRDD.hasSampleAggregateOperator(MongoRDD.scala:221)\r\n\tat com.mongodb.spark.sql.MongoInferSchema$.apply(MongoInferSchema.scala:68)\r\n\tat com.mongodb.spark.sql.DefaultSource.constructRelation(DefaultSource.scala:97)\r\n\tat com.mongodb.spark.sql.DefaultSource.createRelation(DefaultSource.scala:50)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\r\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:171)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "collection_list = ['Research_2007_2013', 'Research_2007_2013_org', 'Research_2007_2013_themes',\\\n",
    "                  'Research_2014_2020', 'Research_2014_2020_org', 'Research_2014_2020_themes',\\\n",
    "                  'Research_2021_2027', 'Research_2021_2027_org', 'Research_2021_2027_themes',\\\n",
    "                  'OCDE_ind']\n",
    "    \n",
    "def extract_collection(collection):\n",
    "    spark.conf.set('spark.sql.caseSensitive', True)\n",
    "    \n",
    "    df_collection = spark.read\\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"uri\", \"mongodb://localhost:27017/Project6\") \\\n",
    "    .option(\"database\", \"Project6\") \\\n",
    "    .option(\"collection\", collection) \\\n",
    "    .load()\n",
    "    return df_collection\n",
    "\n",
    "result = list(map(extract_collection, collection_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf76b5-a187-48a4-8e34-372bed7c98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the size of the df's\n",
    "print(collection_list[0], 'has ',result[0].count(), 'rows and ', len(result[0].columns), 'columns')\n",
    "print(collection_list[1], 'has ',result[1].count(), 'rows and ', len(result[1].columns), 'columns')\n",
    "print(collection_list[2], 'has ',result[2].count(), 'rows and ', len(result[2].columns), 'columns')\n",
    "print(collection_list[3], 'has ',result[3].count(), 'rows and ', len(result[3].columns), 'columns')\n",
    "print(collection_list[4], 'has ',result[4].count(), 'rows and ', len(result[4].columns), 'columns')\n",
    "print(collection_list[5], 'has ',result[5].count(), 'rows and ', len(result[5].columns), 'columns')\n",
    "print(collection_list[6], 'has ',result[6].count(), 'rows and ', len(result[6].columns), 'columns')\n",
    "print(collection_list[7], 'has ',result[7].count(), 'rows and ', len(result[7].columns), 'columns')\n",
    "print(collection_list[8], 'has ',result[8].count(), 'rows and ', len(result[8].columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3846d8f2-027e-478b-92e3-27480d497335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_x = [0, 1, 2]\n",
    "\n",
    "# def printing(x):\n",
    "#     print (collection_list[x], 'has ',result[x].count(), 'rows and ', len(result[x].columns), 'columns')\n",
    "    \n",
    "# list(map(printing(list_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c91fd-0745-4107-afb9-7f7af9614d0f",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a89d73-1ea6-42c4-bfff-c12c3dfd0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df81b7-4fea-4148-bd08-20a162817c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns on MAIN research dataframes\n",
    "columns_main_07_13 = ('acronym', 'status', 'legalBasis', 'topics', 'subCall', 'fundingScheme', 'contentUpdateDate', 'nature')\n",
    "columns_main_other = ('acronym', 'status', 'legalBasis', 'topics', 'subCall', 'fundingScheme', 'contentUpdateDate', 'ecSignatureDate', 'grantDoi', 'masterCall', 'nature')\n",
    "\n",
    "research_2007_2013 = result[0].drop(*columns_main_07_13)\n",
    "research_2014_2020 = result[3].drop(*columns_main_other)\n",
    "research_2021_2027 = result[6].drop(*columns_main_other)\n",
    "\n",
    "#check number of columns\n",
    "print('The number of columns before drop were ', len(result[0].columns), 'and now are ', len(research_2007_2013.columns))\n",
    "print('The number of columns before drop were ', len(result[3].columns), 'and now are ', len(research_2014_2020.columns))\n",
    "print('The number of columns before drop were ', len(result[6].columns), 'and now are ', len(research_2014_2020.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd3203-fa03-40de-96d2-61374f7d0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns on ORG research dataframes\n",
    "columns_org_07_13 = ('projectAcronym', 'vatNumber', 'street', 'postCode', 'organizationURL', 'contactForm', 'contentUpdateDate', 'endOfParticipation')\n",
    "columns_org_other = ('projectAcronym', 'vatNumber', 'street', 'postCode', 'organizationURL', 'contactForm', 'contentUpdateDate', 'endOfParticipation', 'SME', 'active', 'totalCost', 'netEcContribution')\n",
    "\n",
    "research_2007_2013_org = result[1].drop(*columns_org_07_13)\n",
    "research_2014_2020_org = result[4].drop(*columns_org_other)\n",
    "research_2021_2027_org = result[7].drop(*columns_org_other)\n",
    "\n",
    "#check number of columns\n",
    "print('The number of columns before drop were ', len(result[1].columns), 'and now are ', len(research_2007_2013_org.columns))\n",
    "print('The number of columns before drop were ', len(result[4].columns), 'and now are ', len(research_2014_2020_org.columns))\n",
    "print('The number of columns before drop were ', len(result[7].columns), 'and now are ', len(research_2014_2020_org.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681e8d2-8099-4d57-b359-48efd8dd03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all main research df's\n",
    "\n",
    "df_merge = research_2007_2013.unionAll(research_2014_2020)\n",
    "df_research_main = df_merge.unionAll(research_2021_2027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5dea4-f52d-4c2d-a58f-57fd7ab3a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column ecContribution% on research main\n",
    "\n",
    "df_research_main.withColumn(\"% EcContibution\", df_research_main.ecMaxContribution*100/df_research_main.totalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71627b-cdf4-4416-9724-297c3995303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column start year\n",
    "\n",
    "df_research_main = df_research_main.withColumn('start_year', split(df_research_main['startDate'], '-').getItem(0)) \\\n",
    "       .withColumn('end_year', split(df_research_main['endDate'], '-').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41e6a6-4d9d-4cd8-9023-64635f1afb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all org research df's\n",
    "\n",
    "df_merge1 = research_2007_2013_org.unionAll(research_2014_2020_org)\n",
    "df_research_org = df_merge1.unionAll(research_2021_2027_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f58c6a-521e-49ab-aa9f-25772fd8291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column activityType_name on research org\n",
    "\n",
    "df_research_org = df_research_org.withColumn(\"activityType_name\", expr(\"CASE WHEN activityType = 'HES' THEN 'Education Establishments' \" + \n",
    "               \"WHEN activityType = 'REC' THEN 'Research Organisations' WHEN activityType = 'PRC' THEN 'Private sector' \\\n",
    "               WHEN activityType = 'PRC' THEN 'Private sector' \\\n",
    "               WHEN activityType = 'PUB' THEN 'Public bodies' \\\n",
    "               WHEN activityType = 'OTH' THEN 'Other' \\\n",
    "               WHEN activityType IS NULL THEN 'Not_considered'\" +\\\n",
    "               \"ELSE activityType END\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ed0a0-d3b5-462a-a54c-d8450dab78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split column geolocation on research org\n",
    "\n",
    "df_research_org = df_research_org.withColumn('latitude', split(df_research_org['geolocation'], ',').getItem(0)) \\\n",
    "       .withColumn('longitude', split(df_research_org['geolocation'], ',').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991af4a1-dfc0-48a0-9d8d-de607226398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all themes research df's\n",
    "\n",
    "#check column names\n",
    "print(result[2].schema.names)\n",
    "print(result[5].schema.names)\n",
    "print(result[8].schema.names)\n",
    "#ok to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e7f8b-12b4-4e6b-8341-0f2f1f967d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = result[2].unionAll(result[5])\n",
    "df_research_themes = df_merge2.unionAll(result[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b431c-ee73-47d2-9546-faf381c14b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split column path in THEMES research dataframes\n",
    "cols_to_drop = ('to_drop', 'sub_sub_path')\n",
    "\n",
    "\n",
    "df_research_themes = df_research_themes.withColumn('to_drop', split(df_research_themes['euroSciVocPath'], '/').getItem(0)) \\\n",
    "        .withColumn('main_path', split(df_research_themes['euroSciVocPath'], '/').getItem(1)) \\\n",
    "        .withColumn('sub_path', split(df_research_themes['euroSciVocPath'], '/').getItem(2)) \\\n",
    "        .withColumn('sub_sub_path', split(df_research_themes['euroSciVocPath'], '/').getItem(3)) \\\n",
    "        .drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5978ce-71bb-4757-9684-ba5d8f735bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all dfs\n",
    "df_research_main_org = df_research_org.join(df_research_main,df_research_org[\"projectID\"] == df_research_main[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3619a-e5e2-43e1-9136-d12b87b931ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research_all = df_research_main_org.join(df_research_themes,df_research_main_org[\"projectID\"] == df_research_themes[\"projectID\"]).drop('_id', 'projectID', 'rcn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff60e0-baa2-4879-ad43-4850697f10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_time_sum = (df_OCDE_ind.groupby('TIME')\\\n",
    "# .agg(sum('Value')\\\n",
    "# .alias('sum'))\\\n",
    "# .sort(col('TIME')\\\n",
    "# .desc()))\n",
    "\n",
    "# df_time_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a836ed-d617-4afe-a840-1ea0ffeae372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research_all.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d900a2c-bdff-40d8-8307-21ed08b81836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where nans\n",
    "\n",
    "print('Before drop start_year: ', df_research_all.count())\n",
    "df_research_all = df_research_all.na.drop(subset=['start_year'])\n",
    "print('After drop start_year: ', df_research_all.count())\n",
    "\n",
    "print('Before drop country: ', df_research_all.count())\n",
    "df_research_all = df_research_all.na.drop(subset=['country'])\n",
    "print('After drop country: ', df_research_all.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eedc0b1-16b3-46b3-a289-5daa8632f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify country codes\n",
    "(df_research_all.groupby('country')\n",
    ".agg(count('id')\n",
    ".alias('count'))\n",
    ".sort(col('count')\n",
    ".desc())\n",
    ".show(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87f683-494a-44d0-8a5a-edc246bba0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #rename country codes\n",
    "\n",
    "# df_research_all = df_research_all.withColumn(\"country_name\", expr(\"CASE WHEN country = 'DE' THEN 'Germany' \" + \n",
    "#                \"WHEN country = 'UK' THEN 'United Kingdom' \\\n",
    "#                WHEN country = 'ES' THEN 'Spain' \\\n",
    "#                WHEN country = 'FR' THEN 'France' \\\n",
    "#                WHEN country = 'IT' THEN 'Italy' \\\n",
    "#                WHEN country = 'NL' THEN 'Netherlands' \\\n",
    "#                WHEN country = 'BE' THEN 'Belgium' \\\n",
    "#                WHEN country = 'CH' THEN 'Switzerland' \\\n",
    "#                WHEN country = 'EL' THEN 'Greece' \\\n",
    "#                WHEN country = 'SE' THEN 'Sweden' \\\n",
    "#                WHEN country = 'AT' THEN 'Austria' \\\n",
    "#                WHEN country = 'DK' THEN 'Denmark' \\\n",
    "#                WHEN country = 'PT' THEN 'Portugal' \\\n",
    "#                WHEN country = 'FI' THEN 'Finland' \\\n",
    "#                WHEN country = 'NO' THEN 'Norway' \\\n",
    "#                WHEN country = 'IE' THEN 'Ireland' \\\n",
    "#                WHEN country = 'PL' THEN 'Poland' \\\n",
    "#                WHEN country = 'IL' THEN 'Israel' \\\n",
    "#                WHEN country = 'CZ' THEN 'Czech Republic' \\\n",
    "#                WHEN country = 'US' THEN 'United States' \\\n",
    "#                WHEN country IS NULL THEN 'Not_considered'\" +\\\n",
    "#                \"ELSE activityType END\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0396dc-5f26-45c4-97a8-4fbe87b7bcb3",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895693c0-9fd3-4492-b73a-d2482f6fe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_research_all.write \\\n",
    "#   .format(\"jdbc\") \\\n",
    "#   .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "#   .option(\"url\", \"jdbc:mysql://localhost:3306/Project6\") \\\n",
    "#   .option(\"dbtable\", \"df_research_all\") \\\n",
    "#   .option(\"user\", \"root\") \\\n",
    "#   .option(\"password\", \"M1a2r3t4a5!\") \\\n",
    "#   .mode('overwrite') \\\n",
    "#   .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba36cf-8c14-46f6-9b90-6fc59f8e3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_research_all.write \\\n",
    "#   .format(\"jdbc\") \\\n",
    "#   .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "#   .option(\"url\", \"jdbc:mysql://localhost:3306/Project6\") \\\n",
    "#   .option(\"dbtable\", \"df_research_all_new_new\") \\\n",
    "#   .option(\"user\", \"root\") \\\n",
    "#   .option(\"password\", \"M1a2r3t4a5!\") \\\n",
    "#   .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
