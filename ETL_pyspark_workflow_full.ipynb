{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88fcc6a-6dbd-4ded-8017-c6da40578e23",
   "metadata": {},
   "source": [
    "## Imports and Initialization of script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b684bb0a-46de-4a1b-a2ac-a10eca7a2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\marta\\anaconda3\\envs\\data\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\marta\\anaconda3\\envs\\data\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['HADOOP_HOME'] = \"C:\\Hadoop\"\n",
    "sys.path.append(\"C:\\Hadoop\\bin\")\n",
    "\n",
    "os.environ['JAVA_HOME'] = \"C:\\Java\"\n",
    "sys.path.append(\"C:\\Java\\bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4a531b7-77ec-47b0-8ab0-6e2e6355bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,count, round, col, asc, DataFrame, expr, split, lit\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from functools import reduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fe50dca-e3f1-4c89-9c39-6323f3b97d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "builder.\\\n",
    "appName(\"pyspark-notebook2\").\\\n",
    "master(\"local\").\\\n",
    "config(\"spark.executor.memory\", \"1g\").\\\n",
    "config(\"spark.mongodb.input.uri\",\"mongodb://127.0.0.1/Project6\").\\\n",
    "config(\"spark.mongodb.output.uri\",\"mongodb://127.0.0.1/Project6\").\\\n",
    "config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.0\").\\\n",
    "config(\"spark.jars\", \"\\Spark\\spark-3.3.1-bin-hadoop3\\jars\\mysql-connector-j-8.0.32.jar\").\\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb1a0c23-e4b0-41cf-be01-916a76a7c8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From local[5]1\n",
      "parallelize : 6\n",
      "Repartition size : 5\n",
      "Repartition size : 5\n"
     ]
    }
   ],
   "source": [
    "# optimization of speed\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"500\")\n",
    "\n",
    "Rdd = spark.sparkContext.parallelize((0,20))\n",
    "print(\"From local[5]\"+str(Rdd.getNumPartitions()))\n",
    "\n",
    "Rdd1 = spark.sparkContext.parallelize((0,25), 6)\n",
    "print(\"parallelize : \"+str(Rdd1.getNumPartitions()))\n",
    "# Rdd1.saveAsTextFile(\"/FileStore/tables/partition22\")\n",
    "\n",
    "# Using repartition() function\n",
    "Rdd2 = Rdd1.repartition(5)\n",
    "print(\"Repartition size : \" + str(Rdd2.getNumPartitions()))\n",
    "# Rdd2.saveAsTextFile(\"/FileStore/tables/re-partition22\")\n",
    "\n",
    "# Using coalesce() function\n",
    "Rdd3 = Rdd1.coalesce(5)\n",
    "print(\"Repartition size : \" + str(Rdd3.getNumPartitions()))\n",
    "# Rdd3.saveAsTextFile(\"/FileStore/tables/coalesce22\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fd8c3b-dd1b-4aeb-accf-536b51949d0d",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aa5ae5-e681-43c9-9913-b987b73b05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_list = ['Research_2007_2013', 'Research_2007_2013_org', 'Research_2007_2013_themes',\\\n",
    "                  'Research_2014_2020', 'Research_2014_2020_org', 'Research_2014_2020_themes',\\\n",
    "                  'Research_2021_2027', 'Research_2021_2027_org', 'Research_2021_2027_themes',\\\n",
    "                  'OCDE_ind']\n",
    "    \n",
    "def extract_collection(collection):\n",
    "    spark.conf.set('spark.sql.caseSensitive', True)\n",
    "    \n",
    "    df_collection = spark.read\\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"uri\", \"mongodb://localhost:27017/Project6\") \\\n",
    "    .option(\"database\", \"Project6\") \\\n",
    "    .option(\"collection\", collection) \\\n",
    "    .load()\n",
    "    return df_collection\n",
    "\n",
    "result = list(map(extract_collection, collection_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64cf76b5-a187-48a4-8e34-372bed7c98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research_2007_2013 has  25785 rows and  18 columns\n",
      "Research_2007_2013_org has  140055 rows and  21 columns\n",
      "Research_2007_2013_themes has  68651 rows and  5 columns\n",
      "Research_2014_2020 has  35382 rows and  21 columns\n",
      "Research_2014_2020_org has  177078 rows and  25 columns\n",
      "Research_2014_2020_themes has  122551 rows and  5 columns\n",
      "Research_2021_2027 has  5250 rows and  20 columns\n",
      "Research_2021_2027_org has  36680 rows and  24 columns\n",
      "Research_2021_2027_themes has  15810 rows and  5 columns\n"
     ]
    }
   ],
   "source": [
    "#check the size of the df's\n",
    "print(collection_list[0], 'has ',result[0].count(), 'rows and ', len(result[0].columns), 'columns')\n",
    "print(collection_list[1], 'has ',result[1].count(), 'rows and ', len(result[1].columns), 'columns')\n",
    "print(collection_list[2], 'has ',result[2].count(), 'rows and ', len(result[2].columns), 'columns')\n",
    "print(collection_list[3], 'has ',result[3].count(), 'rows and ', len(result[3].columns), 'columns')\n",
    "print(collection_list[4], 'has ',result[4].count(), 'rows and ', len(result[4].columns), 'columns')\n",
    "print(collection_list[5], 'has ',result[5].count(), 'rows and ', len(result[5].columns), 'columns')\n",
    "print(collection_list[6], 'has ',result[6].count(), 'rows and ', len(result[6].columns), 'columns')\n",
    "print(collection_list[7], 'has ',result[7].count(), 'rows and ', len(result[7].columns), 'columns')\n",
    "print(collection_list[8], 'has ',result[8].count(), 'rows and ', len(result[8].columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3846d8f2-027e-478b-92e3-27480d497335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_x = [0, 1, 2]\n",
    "\n",
    "# def printing(x):\n",
    "#     print (collection_list[x], 'has ',result[x].count(), 'rows and ', len(result[x].columns), 'columns')\n",
    "    \n",
    "# list(map(printing(list_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b8f0136-7da4-4f84-85cf-b97c4e14f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the industry dataset\n",
    "OCDE_ind = spark.read\\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"uri\", \"mongodb://localhost:27017/Project6\") \\\n",
    "    .option(\"database\", \"Project6\") \\\n",
    "    .option(\"collection\", 'OCDE_ind') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c91fd-0745-4107-afb9-7f7af9614d0f",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a89d73-1ea6-42c4-bfff-c12c3dfd0dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53df81b7-4fea-4148-bd08-20a162817c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns before drop were  18 and now are  10\n",
      "The number of columns before drop were  21 and now are  10\n",
      "The number of columns before drop were  20 and now are  10\n"
     ]
    }
   ],
   "source": [
    "#drop columns on MAIN research dataframes\n",
    "columns_main_07_13 = ('acronym', 'status', 'legalBasis', 'topics', 'subCall', 'fundingScheme', 'contentUpdateDate', 'nature')\n",
    "columns_main_other = ('acronym', 'status', 'legalBasis', 'topics', 'subCall', 'fundingScheme', 'contentUpdateDate', 'ecSignatureDate', 'grantDoi', 'masterCall', 'nature')\n",
    "\n",
    "research_2007_2013 = result[0].drop(*columns_main_07_13)\n",
    "research_2014_2020 = result[3].drop(*columns_main_other)\n",
    "research_2021_2027 = result[6].drop(*columns_main_other)\n",
    "\n",
    "#check number of columns\n",
    "print('The number of columns before drop were ', len(result[0].columns), 'and now are ', len(research_2007_2013.columns))\n",
    "print('The number of columns before drop were ', len(result[3].columns), 'and now are ', len(research_2014_2020.columns))\n",
    "print('The number of columns before drop were ', len(result[6].columns), 'and now are ', len(research_2014_2020.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbd3203-fa03-40de-96d2-61374f7d0aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns before drop were  21 and now are  13\n",
      "The number of columns before drop were  25 and now are  13\n",
      "The number of columns before drop were  24 and now are  13\n"
     ]
    }
   ],
   "source": [
    "#drop columns on ORG research dataframes\n",
    "columns_org_07_13 = ('projectAcronym', 'vatNumber', 'street', 'postCode', 'organizationURL', 'contactForm', 'contentUpdateDate', 'endOfParticipation')\n",
    "columns_org_other = ('projectAcronym', 'vatNumber', 'street', 'postCode', 'organizationURL', 'contactForm', 'contentUpdateDate', 'endOfParticipation', 'SME', 'active', 'totalCost', 'netEcContribution')\n",
    "\n",
    "research_2007_2013_org = result[1].drop(*columns_org_07_13)\n",
    "research_2014_2020_org = result[4].drop(*columns_org_other)\n",
    "research_2021_2027_org = result[7].drop(*columns_org_other)\n",
    "\n",
    "#check number of columns\n",
    "print('The number of columns before drop were ', len(result[1].columns), 'and now are ', len(research_2007_2013_org.columns))\n",
    "print('The number of columns before drop were ', len(result[4].columns), 'and now are ', len(research_2014_2020_org.columns))\n",
    "print('The number of columns before drop were ', len(result[7].columns), 'and now are ', len(research_2014_2020_org.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b681e8d2-8099-4d57-b359-48efd8dd03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all main research df's\n",
    "\n",
    "df_merge = research_2007_2013.unionAll(research_2014_2020)\n",
    "df_research_main = df_merge.unionAll(research_2021_2027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ef5dea4-f52d-4c2d-a58f-57fd7ab3a406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<oid:string>, ecMaxContribution: int, endDate: timestamp, frameworkProgramme: string, id: string, objective: string, rcn: string, startDate: timestamp, title: string, totalCost: double, % EcContibution: double]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new column ecContribution% on research main\n",
    "\n",
    "df_research_main.withColumn(\"% EcContibution\", df_research_main.ecMaxContribution*100/df_research_main.totalCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b71627b-cdf4-4416-9724-297c3995303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column start year\n",
    "\n",
    "df_research_main = df_research_main.withColumn('start_year', split(df_research_main['startDate'], '-').getItem(0)) \\\n",
    "       .withColumn('end_year', split(df_research_main['endDate'], '-').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f41e6a6-4d9d-4cd8-9023-64635f1afb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all org research df's\n",
    "\n",
    "df_merge1 = research_2007_2013_org.unionAll(research_2014_2020_org)\n",
    "df_research_org = df_merge1.unionAll(research_2021_2027_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9f58c6a-521e-49ab-aa9f-25772fd8291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column activityType_name on research org\n",
    "\n",
    "df_research_org = df_research_org.withColumn(\"activityType_name\", expr(\"CASE WHEN activityType = 'HES' THEN 'Education Establishments' \" + \n",
    "               \"WHEN activityType = 'REC' THEN 'Research Organisations' WHEN activityType = 'PRC' THEN 'Private sector' \\\n",
    "               WHEN activityType = 'PRC' THEN 'Private sector' \\\n",
    "               WHEN activityType = 'PUB' THEN 'Public bodies' \\\n",
    "               WHEN activityType = 'OTH' THEN 'Other' \\\n",
    "               WHEN activityType IS NULL THEN 'Not_considered'\" +\\\n",
    "               \"ELSE activityType END\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c6ed0a0-d3b5-462a-a54c-d8450dab78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split column geolocation on research org\n",
    "\n",
    "df_research_org = df_research_org.withColumn('latitude', split(df_research_org['geolocation'], ',').getItem(0)) \\\n",
    "       .withColumn('longitude', split(df_research_org['geolocation'], ',').getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "991af4a1-dfc0-48a0-9d8d-de607226398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_id', 'euroSciVocCode', 'euroSciVocPath', 'euroSciVocTitle', 'projectID']\n",
      "['_id', 'euroSciVocCode', 'euroSciVocPath', 'euroSciVocTitle', 'projectID']\n",
      "['_id', 'euroSciVocCode', 'euroSciVocPath', 'euroSciVocTitle', 'projectID']\n"
     ]
    }
   ],
   "source": [
    "#merge all themes research df's\n",
    "\n",
    "#check column names\n",
    "print(result[2].schema.names)\n",
    "print(result[5].schema.names)\n",
    "print(result[8].schema.names)\n",
    "#ok to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80e7f8b-12b4-4e6b-8341-0f2f1f967d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2 = result[2].unionAll(result[5])\n",
    "df_research_themes = df_merge2.unionAll(result[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "551b431c-ee73-47d2-9546-faf381c14b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split column path in THEMES research dataframes\n",
    "cols_to_drop = ('to_drop', 'sub_sub_path')\n",
    "\n",
    "\n",
    "df_research_themes = df_research_themes.withColumn('to_drop', split(df_research_themes['euroSciVocPath'], '/').getItem(0)) \\\n",
    "        .withColumn('main_path', split(df_research_themes['euroSciVocPath'], '/').getItem(1)) \\\n",
    "        .withColumn('sub_path', split(df_research_themes['euroSciVocPath'], '/').getItem(2)) \\\n",
    "        .withColumn('sub_sub_path', split(df_research_themes['euroSciVocPath'], '/').getItem(3)) \\\n",
    "        .drop(*cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be5978ce-71bb-4757-9684-ba5d8f735bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all dfs\n",
    "df_research_main_org = df_research_org.join(df_research_main,df_research_org[\"projectID\"] == df_research_main[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5b3619a-e5e2-43e1-9136-d12b87b931ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research_all = df_research_main_org.join(df_research_themes,df_research_main_org[\"projectID\"] == df_research_themes[\"projectID\"]).drop('_id', 'projectID', 'rcn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfff60e0-baa2-4879-ad43-4850697f10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_time_sum = (df_OCDE_ind.groupby('TIME')\\\n",
    "# .agg(sum('Value')\\\n",
    "# .alias('sum'))\\\n",
    "# .sort(col('TIME')\\\n",
    "# .desc()))\n",
    "\n",
    "# df_time_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82a836ed-d617-4afe-a840-1ea0ffeae372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activityType',\n",
       " 'city',\n",
       " 'country',\n",
       " 'ecContribution',\n",
       " 'geolocation',\n",
       " 'name',\n",
       " 'order',\n",
       " 'organisationID',\n",
       " 'role',\n",
       " 'shortName',\n",
       " 'activityType_name',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'ecMaxContribution',\n",
       " 'endDate',\n",
       " 'frameworkProgramme',\n",
       " 'id',\n",
       " 'objective',\n",
       " 'startDate',\n",
       " 'title',\n",
       " 'totalCost',\n",
       " 'start_year',\n",
       " 'end_year',\n",
       " 'euroSciVocCode',\n",
       " 'euroSciVocPath',\n",
       " 'euroSciVocTitle',\n",
       " 'main_path',\n",
       " 'sub_path']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_research_all.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d900a2c-bdff-40d8-8307-21ed08b81836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop start_year:  1057621\n",
      "After drop start_year:  1057216\n",
      "After drop country:  1057202\n"
     ]
    }
   ],
   "source": [
    "#drop rows where nans\n",
    "\n",
    "print('Before drop start_year: ', df_research_all.count())\n",
    "df_research_all = df_research_all.na.drop(subset=['start_year'])\n",
    "print('After drop start_year: ', df_research_all.count())\n",
    "\n",
    "df_research_all = df_research_all.na.drop(subset=['country'])\n",
    "print('After drop country: ', df_research_all.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e393e-4537-4e10-85dc-d970b2ea1498",
   "metadata": {},
   "source": [
    "#### Trying ways to optimize speed during pyspark queries in a 1M row df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eedc0b1-16b3-46b3-a289-5daa8632f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default parameters\n",
    "#https://www.projectpro.io/recipes/explain-repartition-and-coalesce-functions-pyspark-databricks\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# (df_research_all.groupby('country')\n",
    "# .agg(count('id')\n",
    "# .alias('count'))\n",
    "# .sort(col('count')\n",
    "# .desc())\n",
    "# .show())\n",
    "# print(f\"Execution time: {time.time() - start_time}\")\n",
    "\n",
    "# Execution time: 73.11822366714478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635f41e7-0623-42e1-9e2d-0da1da2147cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #trying cache\n",
    "# df_research_all.cache()\n",
    "\n",
    "# start_time = time.time()\n",
    "# (df_research_all.groupby('country')\n",
    "# .agg(count('id')\n",
    "# .alias('count'))\n",
    "# .sort(col('count')\n",
    "# .desc())\n",
    "# .show())\n",
    "# print(f\"Execution time: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5363f7e0-0811-4ad2-929c-055f3dcf53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #trying partitions and coalesce\n",
    "# print(df_research_all.rdd.getNumPartitions())\n",
    "\n",
    "\n",
    "# spark.conf.set(\"spark.sql.shuffle.partitions\", \"500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7cea158-e98d-4ae7-90c2-2770090b4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rdd = spark.sparkContext.parallelize((0,20))\n",
    "# print(\"From local[5]\"+str(Rdd.getNumPartitions()))\n",
    "\n",
    "# Rdd1 = spark.sparkContext.parallelize((0,25), 6)\n",
    "# print(\"parallelize : \"+str(Rdd1.getNumPartitions()))\n",
    "# # Rdd1.saveAsTextFile(\"/FileStore/tables/partition22\")\n",
    "\n",
    "# # Using repartition() function\n",
    "# Rdd2 = Rdd1.repartition(5)\n",
    "# print(\"Repartition size : \" + str(Rdd2.getNumPartitions()))\n",
    "# # Rdd2.saveAsTextFile(\"/FileStore/tables/re-partition22\")\n",
    "\n",
    "# # Using coalesce() function\n",
    "# Rdd3 = Rdd1.coalesce(5)\n",
    "# print(\"Repartition size : \" + str(Rdd3.getNumPartitions()))\n",
    "# # Rdd3.saveAsTextFile(\"/FileStore/tables/coalesce22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e04e15cc-943b-47b7-843d-689b45e05c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# (df_research_all.groupby('country')\n",
    "# .agg(count('id')\n",
    "# .alias('count'))\n",
    "# .sort(col('count')\n",
    "# .desc())\n",
    "# .show())\n",
    "# print(f\"Execution time: {time.time() - start_time}\")\n",
    "\n",
    "# Execution time: 15.6615395475815"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a29de-a7ec-4840-97c1-9b8b725f5d5a",
   "metadata": {},
   "source": [
    "#### finished optimization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1f8dc74-cd45-4fe1-aae6-257c084b504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column with country_name from country\n",
    "\n",
    "country_codes = spark.read\\\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "    .option(\"uri\", \"mongodb://localhost:27017/Project6\") \\\n",
    "    .option(\"database\", \"Project6\") \\\n",
    "    .option(\"collection\", 'country_codes') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9b587a-68a0-4d3f-99e9-e0f759b0ae63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'alpha-2',\n",
       " 'alpha-3',\n",
       " 'country-code',\n",
       " 'intermediate-region',\n",
       " 'intermediate-region-code',\n",
       " 'iso_3166-2',\n",
       " 'name',\n",
       " 'region',\n",
       " 'region-code',\n",
       " 'sub-region',\n",
       " 'sub-region-code']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56456af5-7427-472d-b23d-bb6ea5838ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = country_codes.drop(\"country-code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "862a9c28-92d9-46bb-970e-28860ece5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = country_codes.withColumnRenamed(\"name\", \"country_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ace1c1e-7d64-4588-88a7-7774e6e40eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'alpha-2',\n",
       " 'alpha-3',\n",
       " 'intermediate-region',\n",
       " 'intermediate-region-code',\n",
       " 'iso_3166-2',\n",
       " 'country_name',\n",
       " 'region',\n",
       " 'region-code',\n",
       " 'sub-region',\n",
       " 'sub-region-code']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10d8bd5b-38e0-43f6-b992-a5b6ca0d58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research_all = df_research_all.join\\\n",
    "    (country_codes, df_research_all[\"country\"] == country_codes[\"alpha-2\"])\\\n",
    "    .drop('_id', 'alpha-3', \"alpha-2\", 'intermediate-region',\\\n",
    "     'intermediate-region-code',\\\n",
    "     'iso_3166-2',\\\n",
    "     'region',\\\n",
    "     'region-code',\\\n",
    "     'sub-region',\\\n",
    "     'sub-region-code',\n",
    "     'country-code', 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3084a526-8363-497b-b5a3-3785998c40c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activityType',\n",
       " 'city',\n",
       " 'country',\n",
       " 'ecContribution',\n",
       " 'geolocation',\n",
       " 'order',\n",
       " 'organisationID',\n",
       " 'role',\n",
       " 'shortName',\n",
       " 'activityType_name',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'ecMaxContribution',\n",
       " 'endDate',\n",
       " 'frameworkProgramme',\n",
       " 'id',\n",
       " 'objective',\n",
       " 'startDate',\n",
       " 'title',\n",
       " 'totalCost',\n",
       " 'start_year',\n",
       " 'end_year',\n",
       " 'euroSciVocCode',\n",
       " 'euroSciVocPath',\n",
       " 'euroSciVocTitle',\n",
       " 'main_path',\n",
       " 'sub_path',\n",
       " 'country_name']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_research_all.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad3579ba-fe6d-4ae9-8f8d-a6315eab231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        country_name| count|\n",
      "+--------------------+------+\n",
      "|             Germany|132231|\n",
      "|               Spain|107646|\n",
      "|              France|102638|\n",
      "|               Italy| 99160|\n",
      "|         Netherlands| 67784|\n",
      "|             Belgium| 47666|\n",
      "|         Switzerland| 33082|\n",
      "|              Sweden| 32324|\n",
      "|             Austria| 28667|\n",
      "|             Denmark| 24586|\n",
      "|            Portugal| 21615|\n",
      "|             Finland| 21610|\n",
      "|              Norway| 18372|\n",
      "|             Ireland| 17142|\n",
      "|              Poland| 15834|\n",
      "|              Israel| 13190|\n",
      "|             Czechia| 11133|\n",
      "|United States of ...|  9694|\n",
      "|             Hungary|  9445|\n",
      "|             Romania|  8173|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_research_all.groupby('country_name')\n",
    ".agg(count('id')\n",
    ".alias('count'))\n",
    ".sort(col('count')\n",
    ".desc())\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "360e8ce0-5523-409d-affc-4d23f292de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform OCDE dataset\n",
    "OCDE_ind= OCDE_ind.drop('_id', 'IND', \"VAR\", 'LOCATION')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0396dc-5f26-45c4-97a8-4fbe87b7bcb3",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895693c0-9fd3-4492-b73a-d2482f6fe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_research_all.write \\\n",
    "#   .format(\"jdbc\") \\\n",
    "#   .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "#   .option(\"url\", \"jdbc:mysql://localhost:3306/Project6\") \\\n",
    "#   .option(\"dbtable\", \"df_research_all\") \\\n",
    "#   .option(\"user\", \"root\") \\\n",
    "#   .option(\"password\", \"M1a2r3t4a5!\") \\\n",
    "#   .mode('overwrite') \\\n",
    "#   .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96ba36cf-8c14-46f6-9b90-6fc59f8e3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_research_all.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/Project6\") \\\n",
    "  .option(\"dbtable\", \"df_research_all\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"M1a2r3t4a5!\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3ec85cd-a719-47a7-91a4-44171512d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OCDE_ind.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/Project6\") \\\n",
    "  .option(\"dbtable\", \"OCDE_ind\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"M1a2r3t4a5!\") \\\n",
    "  .mode('overwrite').save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
